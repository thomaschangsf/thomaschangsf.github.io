

<!doctype html>






<html  data-paige="Paige theme from https://github.com/willfaught/paige"   lang="en" >

    










    

    

    

    

    

    

    

    

    




<head>
    

    

<meta charset="utf-8">




    <meta content="Refresher course on Spark" name="description">




<meta content="#0d6efd" name="msapplication-TileColor">


    <meta content="/browserconfig.xml" name="msapplication-config">


<meta content="https://github.com/willfaught/paige" name="theme">
<meta content="#0d6efd" name="theme-color">
<meta content="width=device-width, initial-scale=1" name="viewport">

<meta property="og:url" content="https://example.com/books/software-system/scaling-ml-spark/">
  <meta property="og:title" content="Scaling ML Spark">
  <meta property="og:description" content="Refresher course on Spark">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="books">


  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Scaling ML Spark">
  <meta name="twitter:description" content="Refresher course on Spark">



    
        <title>Scaling ML Spark · Software System ·  · Paige</title>
    

    


    <link href="/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">



    <link href="/favicon.ico" rel="shortcut icon">



    <link href="/favicon.png" rel="icon" type="image/png">



    <link href="/favicon.svg" rel="icon" type="image/svg+xml">



    <link href="/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">



    <link href="/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">



    <link color="#0d6efd" href="/safari-pinned-tab.svg" rel="mask-icon">



    <link href="/site.webmanifest" rel="manifest">
























    

    
        
        
        
    

    
        
    

    
    
    


<link  crossorigin="anonymous"  href="/css/paige/bootstrap/6186ad141d391e4c0c10d2e9cb4eaeaadf75e809-paige.min.1c5bb4860fb7f3809f4195b145668aade87f2e92cf701992599678b1d166f0f0.css"  integrity="sha256-HFu0hg&#43;384CfQZWxRWaKreh/LpLPcBmSWZZ4sdFm8PA="   referrerpolicy="no-referrer"  rel="stylesheet">



















    

    

    

    
    
    


<link  crossorigin="anonymous"  href="/css/paige/bootstrap-icons/bootstrap-icons.min.540116b7267d4b2410c74086ae6497566928c6d5715900be7ce7279ad45addcd.css"  integrity="sha256-VAEWtyZ9SyQQx0CGrmSXVmkoxtVxWQC&#43;fOcnmtRa3c0="   referrerpolicy="no-referrer"  rel="stylesheet">



    

















    

    

    

    
    
    


<link  crossorigin="anonymous"  href="/css/paige/katex/katex.min.min.c12d9cca9aa0af743d947ef8c8f5fabaad13e5b4c9fed061fbdf7c9d3c387581.css"  integrity="sha256-wS2cypqgr3Q9lH74yPX6uq0T5bTJ/tBh&#43;998nTw4dYE="   referrerpolicy="no-referrer"  rel="stylesheet">





    

<style>


.paige-figure-numbered {
    counter-increment: paige-figure-numbered;
}

.paige-figure-numbered > div > figure > figcaption::before {
    content: "Figure " counter(paige-figure-numbered) ": ";
}

.paige-figure-numbered > div > figure > figcaption:empty::before {
    content: "Figure " counter(paige-figure-numbered);
}

.paige-header-link {
    opacity: 0;
    margin-left: 0.5rem;
    position: absolute;
    transition: color 0.15s ease-in-out, opacity 0.15s ease-in-out;
}

.paige-header-link::after {
    content: "#";
}

.paige-quote .blockquote-footer {
    margin-top: 0;
}

.paige-quote blockquote {
    border-left: 0;
    border-right: 0;
    margin-bottom: 0;
    padding: 0;
}

#paige-content > * {
    margin-bottom: 1rem;
}

blockquote {
    padding: 0.5rem 1rem;
    border-left: 0.25rem solid var(--bs-border-color);
    border-right: 0.25rem solid var(--bs-body-bg);
}

td, th {
    padding: 0.25rem;
}

.highlight .chroma .hl,
.highlight .chroma .lnt {
    display: flex;
}

.paige-figure .paige-quote,
.paige-figure .paige-video,
.paige-figure .highlight pre.chroma,
.paige-figure .highlight .chroma pre,
.paige-figure .paige-quote blockquote,
.paige-figure figure > div > :last-child,
.paige-gallery .paige-figure,
.paige-gallery .paige-image,
blockquote > p:last-of-type {
    margin-bottom: 0;
}

.paige-figure,
.paige-gallery,
.paige-image,
.paige-quote,
.paige-video,
table {
    margin-bottom: 1rem;
}

.paige-header-link:focus,
.paige-header-link:hover,
:hover > .paige-header-link,
:target > .paige-header-link {
    opacity: 1;
}




    @media (prefers-color-scheme: dark) {
        /* Background */ .bg { color: #c9d1d9; background-color: var(--bs-body-bg); }
/* PreWrapper */ .chroma { color: #c9d1d9; background-color: var(--bs-body-bg); }
/* Other */ .chroma .x {  }
/* Error */ .chroma .err { color: #f85149 }
/* CodeLine */ .chroma .cl {  }
/* LineLink */ .chroma .lnlinks { outline: none; text-decoration: none; color: inherit }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0; }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0; }
/* LineHighlight */ .chroma .hl { background-color: #4f4f4d }
/* LineNumbersTable */ .chroma .lnt { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #64686c }
/* LineNumbers */ .chroma .ln { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #6e7681 }
/* Line */ .chroma .line { display: flex; }
/* Keyword */ .chroma .k { color: #ff7b72 }
/* KeywordConstant */ .chroma .kc { color: #79c0ff }
/* KeywordDeclaration */ .chroma .kd { color: #ff7b72 }
/* KeywordNamespace */ .chroma .kn { color: #ff7b72 }
/* KeywordPseudo */ .chroma .kp { color: #79c0ff }
/* KeywordReserved */ .chroma .kr { color: #ff7b72 }
/* KeywordType */ .chroma .kt { color: #ff7b72 }
/* Name */ .chroma .n {  }
/* NameAttribute */ .chroma .na {  }
/* NameBuiltin */ .chroma .nb {  }
/* NameBuiltinPseudo */ .chroma .bp {  }
/* NameClass */ .chroma .nc { color: #f0883e; font-weight: bold }
/* NameConstant */ .chroma .no { color: #79c0ff; font-weight: bold }
/* NameDecorator */ .chroma .nd { color: #d2a8ff; font-weight: bold }
/* NameEntity */ .chroma .ni { color: #ffa657 }
/* NameException */ .chroma .ne { color: #f0883e; font-weight: bold }
/* NameFunction */ .chroma .nf { color: #d2a8ff; font-weight: bold }
/* NameFunctionMagic */ .chroma .fm {  }
/* NameLabel */ .chroma .nl { color: #79c0ff; font-weight: bold }
/* NameNamespace */ .chroma .nn { color: #ff7b72 }
/* NameOther */ .chroma .nx {  }
/* NameProperty */ .chroma .py { color: #79c0ff }
/* NameTag */ .chroma .nt { color: #7ee787 }
/* NameVariable */ .chroma .nv { color: #79c0ff }
/* NameVariableClass */ .chroma .vc {  }
/* NameVariableGlobal */ .chroma .vg {  }
/* NameVariableInstance */ .chroma .vi {  }
/* NameVariableMagic */ .chroma .vm {  }
/* Literal */ .chroma .l { color: #a5d6ff }
/* LiteralDate */ .chroma .ld { color: #79c0ff }
/* LiteralString */ .chroma .s { color: #a5d6ff }
/* LiteralStringAffix */ .chroma .sa { color: #79c0ff }
/* LiteralStringBacktick */ .chroma .sb { color: #a5d6ff }
/* LiteralStringChar */ .chroma .sc { color: #a5d6ff }
/* LiteralStringDelimiter */ .chroma .dl { color: #79c0ff }
/* LiteralStringDoc */ .chroma .sd { color: #a5d6ff }
/* LiteralStringDouble */ .chroma .s2 { color: #a5d6ff }
/* LiteralStringEscape */ .chroma .se { color: #79c0ff }
/* LiteralStringHeredoc */ .chroma .sh { color: #79c0ff }
/* LiteralStringInterpol */ .chroma .si { color: #a5d6ff }
/* LiteralStringOther */ .chroma .sx { color: #a5d6ff }
/* LiteralStringRegex */ .chroma .sr { color: #79c0ff }
/* LiteralStringSingle */ .chroma .s1 { color: #a5d6ff }
/* LiteralStringSymbol */ .chroma .ss { color: #a5d6ff }
/* LiteralNumber */ .chroma .m { color: #a5d6ff }
/* LiteralNumberBin */ .chroma .mb { color: #a5d6ff }
/* LiteralNumberFloat */ .chroma .mf { color: #a5d6ff }
/* LiteralNumberHex */ .chroma .mh { color: #a5d6ff }
/* LiteralNumberInteger */ .chroma .mi { color: #a5d6ff }
/* LiteralNumberIntegerLong */ .chroma .il { color: #a5d6ff }
/* LiteralNumberOct */ .chroma .mo { color: #a5d6ff }
/* Operator */ .chroma .o { color: #ff7b72; font-weight: bold }
/* OperatorWord */ .chroma .ow { color: #ff7b72; font-weight: bold }
/* Punctuation */ .chroma .p {  }
/* Comment */ .chroma .c { color: #8b949e; font-style: italic }
/* CommentHashbang */ .chroma .ch { color: #8b949e; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #8b949e; font-style: italic }
/* CommentSingle */ .chroma .c1 { color: #8b949e; font-style: italic }
/* CommentSpecial */ .chroma .cs { color: #8b949e; font-weight: bold; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #8b949e; font-weight: bold; font-style: italic }
/* CommentPreprocFile */ .chroma .cpf { color: #8b949e; font-weight: bold; font-style: italic }
/* Generic */ .chroma .g {  }
/* GenericDeleted */ .chroma .gd { color: #ffa198; background-color: #490202 }
/* GenericEmph */ .chroma .ge { font-style: italic }
/* GenericError */ .chroma .gr { color: #ffa198 }
/* GenericHeading */ .chroma .gh { color: #79c0ff; font-weight: bold }
/* GenericInserted */ .chroma .gi { color: #56d364; background-color: #0f5323 }
/* GenericOutput */ .chroma .go { color: #8b949e }
/* GenericPrompt */ .chroma .gp { color: #8b949e }
/* GenericStrong */ .chroma .gs { font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #79c0ff }
/* GenericTraceback */ .chroma .gt { color: #ff7b72 }
/* GenericUnderline */ .chroma .gl { text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #6e7681 }

    }

    @media (prefers-color-scheme: light) {
        /* Background */ .bg { background-color: #ffffff; }
/* PreWrapper */ .chroma { background-color: #ffffff; }
/* Other */ .chroma .x {  }
/* Error */ .chroma .err { color: #a61717; background-color: #e3d2d2 }
/* CodeLine */ .chroma .cl {  }
/* LineLink */ .chroma .lnlinks { outline: none; text-decoration: none; color: inherit }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0; }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0; }
/* LineHighlight */ .chroma .hl { background-color: #ffffcc }
/* LineNumbersTable */ .chroma .lnt { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #7f7f7f }
/* LineNumbers */ .chroma .ln { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #7f7f7f }
/* Line */ .chroma .line { display: flex; }
/* Keyword */ .chroma .k { color: #000000; font-weight: bold }
/* KeywordConstant */ .chroma .kc { color: #000000; font-weight: bold }
/* KeywordDeclaration */ .chroma .kd { color: #000000; font-weight: bold }
/* KeywordNamespace */ .chroma .kn { color: #000000; font-weight: bold }
/* KeywordPseudo */ .chroma .kp { color: #000000; font-weight: bold }
/* KeywordReserved */ .chroma .kr { color: #000000; font-weight: bold }
/* KeywordType */ .chroma .kt { color: #445588; font-weight: bold }
/* Name */ .chroma .n {  }
/* NameAttribute */ .chroma .na { color: #008080 }
/* NameBuiltin */ .chroma .nb { color: #0086b3 }
/* NameBuiltinPseudo */ .chroma .bp { color: #999999 }
/* NameClass */ .chroma .nc { color: #445588; font-weight: bold }
/* NameConstant */ .chroma .no { color: #008080 }
/* NameDecorator */ .chroma .nd { color: #3c5d5d; font-weight: bold }
/* NameEntity */ .chroma .ni { color: #800080 }
/* NameException */ .chroma .ne { color: #990000; font-weight: bold }
/* NameFunction */ .chroma .nf { color: #990000; font-weight: bold }
/* NameFunctionMagic */ .chroma .fm {  }
/* NameLabel */ .chroma .nl { color: #990000; font-weight: bold }
/* NameNamespace */ .chroma .nn { color: #555555 }
/* NameOther */ .chroma .nx {  }
/* NameProperty */ .chroma .py {  }
/* NameTag */ .chroma .nt { color: #000080 }
/* NameVariable */ .chroma .nv { color: #008080 }
/* NameVariableClass */ .chroma .vc { color: #008080 }
/* NameVariableGlobal */ .chroma .vg { color: #008080 }
/* NameVariableInstance */ .chroma .vi { color: #008080 }
/* NameVariableMagic */ .chroma .vm {  }
/* Literal */ .chroma .l {  }
/* LiteralDate */ .chroma .ld {  }
/* LiteralString */ .chroma .s { color: #dd1144 }
/* LiteralStringAffix */ .chroma .sa { color: #dd1144 }
/* LiteralStringBacktick */ .chroma .sb { color: #dd1144 }
/* LiteralStringChar */ .chroma .sc { color: #dd1144 }
/* LiteralStringDelimiter */ .chroma .dl { color: #dd1144 }
/* LiteralStringDoc */ .chroma .sd { color: #dd1144 }
/* LiteralStringDouble */ .chroma .s2 { color: #dd1144 }
/* LiteralStringEscape */ .chroma .se { color: #dd1144 }
/* LiteralStringHeredoc */ .chroma .sh { color: #dd1144 }
/* LiteralStringInterpol */ .chroma .si { color: #dd1144 }
/* LiteralStringOther */ .chroma .sx { color: #dd1144 }
/* LiteralStringRegex */ .chroma .sr { color: #009926 }
/* LiteralStringSingle */ .chroma .s1 { color: #dd1144 }
/* LiteralStringSymbol */ .chroma .ss { color: #990073 }
/* LiteralNumber */ .chroma .m { color: #009999 }
/* LiteralNumberBin */ .chroma .mb { color: #009999 }
/* LiteralNumberFloat */ .chroma .mf { color: #009999 }
/* LiteralNumberHex */ .chroma .mh { color: #009999 }
/* LiteralNumberInteger */ .chroma .mi { color: #009999 }
/* LiteralNumberIntegerLong */ .chroma .il { color: #009999 }
/* LiteralNumberOct */ .chroma .mo { color: #009999 }
/* Operator */ .chroma .o { color: #000000; font-weight: bold }
/* OperatorWord */ .chroma .ow { color: #000000; font-weight: bold }
/* Punctuation */ .chroma .p {  }
/* Comment */ .chroma .c { color: #999988; font-style: italic }
/* CommentHashbang */ .chroma .ch { color: #999988; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #999988; font-style: italic }
/* CommentSingle */ .chroma .c1 { color: #999988; font-style: italic }
/* CommentSpecial */ .chroma .cs { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #999999; font-weight: bold; font-style: italic }
/* CommentPreprocFile */ .chroma .cpf { color: #999999; font-weight: bold; font-style: italic }
/* Generic */ .chroma .g {  }
/* GenericDeleted */ .chroma .gd { color: #000000; background-color: #ffdddd }
/* GenericEmph */ .chroma .ge { color: #000000; font-style: italic }
/* GenericError */ .chroma .gr { color: #aa0000 }
/* GenericHeading */ .chroma .gh { color: #999999 }
/* GenericInserted */ .chroma .gi { color: #000000; background-color: #ddffdd }
/* GenericOutput */ .chroma .go { color: #888888 }
/* GenericPrompt */ .chroma .gp { color: #555555 }
/* GenericStrong */ .chroma .gs { font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #aaaaaa }
/* GenericTraceback */ .chroma .gt { color: #aa0000 }
/* GenericUnderline */ .chroma .gl { text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #bbbbbb }

    }


@media (prefers-reduced-motion: reduce) {
    .paige-header-link {
        transition: none;
    }
}




</style>


    
</head>

    <body class="d-flex flex-column">

        

        <div class="container flex-fill" id="paige-root">
            <div class="row">
                <div class="col">
                    
                    


    <header class="my-3" id="paige-header">
        

        




        








    





    



    <nav>
        <ul class="align-items-center justify-content-center nav ">
            
                
                
                
                
                

                <li class="nav-item ">
                    <a   class="  nav-link   text-decoration-underline "  href="/"    >Home</a>

                    
                </li>
            
                
                
                
                
                

                <li class="nav-item ">
                    <a  aria-current="page"   class=" active  text-body-emphasis    nav-link   text-decoration-underline "  href="/books/"    >Books</a>

                    
                </li>
            
                
                
                
                
                

                <li class="nav-item ">
                    <a   class="  nav-link   text-decoration-underline "  href="/blogs/"    >Blogs</a>

                    
                </li>
            
                
                
                
                
                

                <li class="nav-item ">
                    <a   class="  nav-link   text-decoration-underline "  href="/resume/"    >Resume</a>

                    
                </li>
            
                
                
                
                
                

                <li class="nav-item ">
                    <a   class="  nav-link   text-decoration-underline "  href="/github/"    >Github</a>

                    
                </li>
            
                
                
                
                
                

                <li class="nav-item ">
                    <a   class="  nav-link   text-decoration-underline "  href="/search/"    >Search</a>

                    
                </li>
            
        </ul>
    </nav>


        

        
    </header>



                    <main class="mt-3" id="paige-main">
                        

                        



















    



    
        
    




<article  class="paige-published paige-single"  id="paige-article">
    <div class="align-items-center d-flex flex-column mb-0">
        













<div class="mw-100" id="paige-metadata">
    
        <h1 class="fw-bold text-center" id="paige-title">Scaling ML Spark</h1>
    

    
        <p class="lead text-center" id="paige-description">Refresher course on Spark</p>
    

    
        <div class="mb-3">
            

            

            

            

            
                <p class="mb-0 text-center text-secondary" id="paige-reading-time">16 minutes</p>
            
        </div>
    
</div>

        



        


    <div class="mw-100" id="paige-toc">
        <div class="border mb-3 pe-3 ps-3 pt-3 rounded">
            <nav id="TableOfContents">
  <ol>
    <li>
      <ol>
        <li><a href="#executing-pyspark-code">Executing PySpark Code</a></li>
        <li><a href="#apache-spark-basics">Apache Spark Basics</a></li>
      </ol>
    </li>
  </ol>

  <ol>
    <li>
      <ol>
        <li><a href="#terminology">Terminology</a></li>
        <li><a href="#common-scenarios-and-options">Common Scenarios and Options</a></li>
      </ol>
    </li>
  </ol>

  <ol>
    <li>
      <ol>
        <li><a href="#61-supervised-ml">6.1 Supervised ML</a>
          <ol>
            <li><a href="#611-classification">6.1.1 Classification</a></li>
            <li><a href="#612-regression">6.1.2 Regression</a></li>
          </ol>
        </li>
        <li><a href="#62-unsupervised">6.2 Unsupervised</a>
          <ol>
            <li><a href="#621-frequent-pattern-mining">6.2.1 Frequent Pattern Mining</a></li>
            <li><a href="#622-clustering">6.2.2 Clustering</a></li>
          </ol>
        </li>
        <li><a href="#63-evaluation">6.3 Evaluation</a>
          <ol>
            <li><a href="#631-supervised">6.3.1 Supervised</a></li>
            <li><a href="#632-unsupervised">6.3.2 Unsupervised</a></li>
          </ol>
        </li>
        <li><a href="#64-hyperparameter-and-tuning-experiments">6.4 Hyperparameter and Tuning Experiments</a>
          <ol>
            <li><a href="#option-1-parameter-grid">Option 1: Parameter Grid</a></li>
            <li><a href="#option-2-cross-validation">Option 2: Cross Validation</a></li>
          </ol>
        </li>
        <li><a href="#65-ml-pipellines">6.5 ML Pipellines</a></li>
      </ol>
    </li>
  </ol>

  <ol>
    <li>
      <ol>
        <li><a href="#2-cluster-approach">2 Cluster Approach</a></li>
        <li><a href="#data-access-layer">Data Access Layer</a></li>
      </ol>
    </li>
  </ol>

  <ol>
    <li>
      <ol>
        <li><a href="#101-deployment-patterns">10.1 Deployment Patterns</a></li>
        <li><a href="#102-monitoring-ml-models-in-production">10.2 Monitoring ML Models In Production</a></li>
        <li><a href="#103-production-feedback-loop">10.3 Production Feedback Loop</a></li>
        <li><a href="#104-deploying-with-mllib">10.4 Deploying with MLLib</a></li>
        <li><a href="#105-deploying-with-mlflow">10.5 Deploying with MLFlow</a>
          <ol>
            <li><a href="#1051-step1-wrap-model-and-meta-in-a-mlflow-wrapper">10.5.1 Step1: Wrap model and meta in a MLflow Wrapper</a></li>
            <li><a href="#1052-option1-deploy-as-a-model-service">10.5.2 Option1: Deploy as a model service</a></li>
            <li><a href="#1053-option2-dploy-as-spark-udf">10.5.3 Option2: Dploy as Spark UDF</a></li>
          </ol>
        </li>
      </ol>
    </li>
  </ol>
</nav>
        </div>
    </div>


        




    <div class="mw-100" id="paige-content"><h1 id="1-distributed-ml-terms-and-concepts">1 Distributed ML Terms and Concepts<a aria-label="Link to this section" class="paige-header-link" href="#1-distributed-ml-terms-and-concepts"></a></h1>
<h1 id="2-intro-to-spark-and-pyspark">2 Intro to Spark and PySpark<a aria-label="Link to this section" class="paige-header-link" href="#2-intro-to-spark-and-pyspark"></a></h1>
<ul>
<li>Driver Program
<ul>
<li>The driver program (aka Spark driver) is a dedicated process that runs on the driver machine. It is responsible for executing and holding the SparkSession, which encapsulates the SparkContext—this is considered the application’s entry point, or the “real program.” The SparkContext contains all the basic functions, context delivered at start time, and information about the cluster. The driver also holds the DAG scheduler, task scheduler, block manager, and everything that is needed to turn the code into jobs that the worker and executors can execute on the cluster. The driver program works in synergy with the cluster manager to find the existing machines and allocated resources.</li>
</ul>
</li>
<li>Executor:
<ul>
<li>Is a process</li>
<li>Has T tasks
<ul>
<li>tasks is smallest unit of work</li>
<li>task in the same executor share the same cache, memory, and global parameters</li>
</ul>
</li>
</ul>
</li>
<li>Worker Node
<ul>
<li>VM</li>
<li>multiple executor on a worker node</li>
</ul>
</li>
<li>Cluster manager
<ul>
<li>Assign executors to worker nodes, assign resources and communicate information about resource availability to driver program</li>
</ul>
</li>
</ul>
<h3 id="executing-pyspark-code">Executing PySpark Code<a aria-label="Link to this section" class="paige-header-link" href="#executing-pyspark-code"></a></h3>
<ul>
<li>Pyspark -&gt;
<ul>
<li>process: python - InterProcess communication (IPC) - process: scala/JVM</li>
<li>JVM spark query optimization, computation, distribution of tasks to clusters</li>
</ul>
</li>
<li>Py4J
<ul>
<li>pyspark driver - pickled item (serialization) - py4j context - Spark driver GVM</li>
<li> <a href="https://www.py4j.org/">Py4J</a> is a library written in Python and Java that enables Python programs running in a Python interpreter to dynamically access Java objects and collections in a JVM via standard Python methods</li>
<li>==PySpark is often less efficient in terms of running time than traditional Scala/Java code==</li>
</ul>
</li>
</ul>
<h3 id="apache-spark-basics">Apache Spark Basics<a aria-label="Link to this section" class="paige-header-link" href="#apache-spark-basics"></a></h3>
<ul>
<li>Architectures</li>
<li>DataFrame vs Datasets
<ul>
<li>Datasets enforces type safety; there is no way to mistaken a col type of string as int</li>
<li>BUT dataset is slower.</li>
</ul>
</li>
</ul>
<h1 id="3-mlflow">3 MLFlow<a aria-label="Link to this section" class="paige-header-link" href="#3-mlflow"></a></h1>
<ul>
<li>
<p>MLOps: manage the machine learning experiment lifecycle</p>
<ul>
<li>term: experiments can be orgainzed as pipeline code or Ml modules in repos</li>
<li>Phases
<ul>
<li>machine learning
<ul>
<li>training, tuning, finding optimal models</li>
</ul>
</li>
<li>development
<ul>
<li>develop ==pipelines== and ==tools== to take ml model from dev/experiment to staging and production</li>
</ul>
</li>
<li>operations
<ul>
<li>CI/CD, monitoring, managing, serving models at scale</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Requirement for ML Lifecycle Management</p>
<ul>
<li>Reproducibility
<ul>
<li>Ability to run your algorithm repeatedly on different datasets and obtain the same (or similar) results. Analyzing, reporting, auditing, and interpreting data are all aspects of this process, meaning each step in the lifecycle needs to be tracked and saved</li>
</ul>
</li>
<li>Code Version Control</li>
<li>Data Version Control
<ul>
<li>Tools: DVC and lakeFS</li>
</ul>
</li>
</ul>
</li>
<li>
<p>ML Flow manages the entire ML lifeycle</p>
<ul>
<li>Component 1: Tracking Server
<ul>
<li>What does it track?
<ul>
<li>Model hyper-parameters</li>
<li>metrics</li>
<li>metadata</li>
<li>artifacts</li>
</ul>
</li>
<li>Runs: everytime you run an experiment, you can tack</li>
<li><code>$ mlflow run example/conda-env/project -P alpha=0.5</code></li>
</ul>
</li>
<li>Compoment 2:  Model Registry
<ul>
<li>Downstream automated job can query the model registry</li>
<li>DS -&gt; model into staging</li>
<li>ML Engineer -&gt; production and archived</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Tbale schema</p>
<ul>
<li>Experiment -&gt; Run</li>
<li>Run -&gt; Metrics, Params, and Tags</li>
</ul>
</li>
</ul>
<h1 id="4-data-ingestion-preprocessing-and-stats">4 Data Ingestion, PreProcessing, and Stats<a aria-label="Link to this section" class="paige-header-link" href="#4-data-ingestion-preprocessing-and-stats"></a></h1>
<h1 id="5-feature-engineering">5 Feature Engineering<a aria-label="Link to this section" class="paige-header-link" href="#5-feature-engineering"></a></h1>
<h3 id="terminology">Terminology<a aria-label="Link to this section" class="paige-header-link" href="#terminology"></a></h3>
<ul>
<li>Estimator : an algorithm that can fit on a Dataframe</li>
</ul>
<h3 id="common-scenarios-and-options">Common Scenarios and Options<a aria-label="Link to this section" class="paige-header-link" href="#common-scenarios-and-options"></a></h3>
<p>Handle Missing Features</p>
<ul>
<li>Approaches
<ul>
<li>drop rows</li>
<li>mean/median</li>
<li>random sample</li>
<li>arbitrary value</li>
<li>missing value indicator</li>
<li>multivariate imputation</li>
</ul>
</li>
<li>Some algorithms are more sensitive to missing values, like SVM, PCA and nearest neighbor because each data point changes the outcome.</li>
</ul>
<p>Extract Feature From Text</p>
<ul>
<li>BOW</li>
<li>TF-IDF</li>
<li>n-gram</li>
<li>word2vec</li>
<li>Topic extraction</li>
</ul>
<p>Categorical Encoding</p>
<ul>
<li>StringToIndex</li>
<li>1 hot encoding</li>
<li>Count and frequency encoding</li>
<li>Ordinal encoding</li>
<li>Weight of eveidence</li>
<li>Rare label encoding</li>
<li>Feature hashing</li>
</ul>
<p>Feature Scaling</p>
<ul>
<li>Normalization</li>
<li>MinMax scaling</li>
<li>Mean scaling</li>
<li>Max absolute scaling</li>
<li>Unit norm scaling</li>
</ul>
<h1 id="6-training-models-with-spark-mllib">6 Training Models with Spark MLLib<a aria-label="Link to this section" class="paige-header-link" href="#6-training-models-with-spark-mllib"></a></h1>
<ul>
<li>Spark model can view its hypermeter documentation</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">	<span class="kn">import</span> <span class="nn">pprint</span> 
</span></span><span class="line"><span class="cl">	<span class="n">pp</span> <span class="o">=</span> <span class="n">pprint</span><span class="o">.</span><span class="n">PrettyPrinter</span><span class="p">(</span><span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">params</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">explainParams</span><span class="p">()</span> 
</span></span><span class="line"><span class="cl">	<span class="n">pp</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="p">(</span><span class="s1">&#39;aggregationDepth: suggested depth for treeAggregate (&gt;= 2). (default: 2)</span><span class="se">\n</span><span class="s1">&#39;</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;featuresCol: features column name. (default: features, current: &#39;</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;selectedFeatures)</span><span class="se">\n</span><span class="s1">&#39;</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;k: Number of independent Gaussians in the mixture model. Must be &gt; 1. &#39;</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;(default: 2, current: 42)</span><span class="se">\n</span><span class="s1">&#39;</span>
</span></span><span class="line"><span class="cl"> <span class="o">....</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><h3 id="61-supervised-ml">6.1 Supervised ML<a aria-label="Link to this section" class="paige-header-link" href="#61-supervised-ml"></a></h3>
<h4 id="611-classification">6.1.1 Classification<a aria-label="Link to this section" class="paige-header-link" href="#611-classification"></a></h4>
<ul>
<li>classification calculates the probability of a data point belong to a class(es) given the input features. Output is a probability that is mapped/thresholded to categorical.
<ul>
<li>Distinction
<ul>
<li>logistic regression outputs the probability of a discrete class (used in binary classfication). LR is classifcation</li>
<li>regression algorithms predictions continuous values</li>
</ul>
</li>
</ul>
</li>
<li>Types of classification
<ul>
<li>Binary
<ul>
<li>Each input is classified into one of two classes (yes or no, true or false, etc.).</li>
</ul>
</li>
<li>Multiclass
<ul>
<li>Each input is classified into one of a set of more than two classes.</li>
</ul>
</li>
<li>Multilabel
<ul>
<li>Each given input can have multiple labels in practice. For example, a sentence might have two sentiment classifications, such as happy and fulfilled. Spark does not support this out of the box; you will need to train each classifier separately and combine the outcomes.</li>
</ul>
</li>
</ul>
</li>
<li>Algorithms
<ul>
<li>Logistic Regression:
<ul>
<li>Binary and multiclass classifier. Can be trained on streaming data with the RDD-based API. Expects an indexed label and a vector of indexed features.</li>
</ul>
</li>
<li>Decision Tree Classifier
<ul>
<li>Binary and multiclass decision tree classifier. Expects an indexed label and a vector of indexed features.</li>
</ul>
</li>
<li>RandomForest Classifier
<ul>
<li>Binary and multiclass classifier. A random forest is a group or ensemble of individual decision trees, each trained on discrete values. Expects an indexed label and a vector of indexed features.</li>
</ul>
</li>
<li>GBTClassifier
<ul>
<li>Binary gradient boosted trees classifier (supported in Spark v3.1.1 and later). Like the <code>RandomForestClassifier</code>, this is an ensemble of decision trees. However, its training process is different; as a result, ==it can be used for regression as well==. Expects an indexed label and a vector of indexed features.</li>
</ul>
</li>
<li>MultiLayer Perception
<ul>
<li>Multiclass classifier based on a feed-forward artificial neural network. Expects layer sizes, a vector of indexed features, and indexed labels.</li>
</ul>
</li>
<li>OneVsRest
<ul>
<li>Used to reduce multiclass classification to binary classification, using a one-versus-all strategy. Expects a binary classifier, a vector of indexed features, and indexed labels.</li>
</ul>
</li>
<li>Naives Bayes
<ul>
<li>Multiclass classifier, considered efficient as it runs only one pass over the training data. Expects a Double for the weight of a data point (to correct for a skewed label distribution), indexed labels, and a vector of indexed features. Returns the probability for each label.</li>
</ul>
</li>
<li>FMClassifier
<ul>
<li>Binary factorization machines classifier. Expects indexed labels and a vector of indexed features.</li>
</ul>
</li>
</ul>
</li>
<li>Sample code</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.ml.classification</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">happy_lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">maxIter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">labelCol</span><span class="o">=</span><span class="s2">&#34;happy_label&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">happy_lr_model</span> <span class="o">=</span> <span class="n">happy_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span>
</span></span></code></pre></div><ul>
<li>How to deal with imbalanced data?
<ul>
<li>Effect: Bias will be toward teh class label with high number of observation bc it is statistically more dominant</li>
<li>Sol 1:  downsize the majority and upsize the minority</li>
<li>Sol 2: Algorms it GBTClassifier, GBTRegression, and RandomForestClassifier has a <a href="https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.classification.RandomForestClassifier.html#pyspark.ml.classification.RandomForestClassifier.featureSubsetStrategy">featureSubsetStrategy</a>. In every tree node, the algorithm processes a random subset of features and uses the result to build the next node</li>
</ul>
</li>
</ul>
<h4 id="612-regression">6.1.2 Regression<a aria-label="Link to this section" class="paige-header-link" href="#612-regression"></a></h4>
<ul>
<li>Types of Regression
<ul>
<li>Simple:
<ul>
<li>There is only one independent and one dependent variable: one value for training and one to predict.</li>
</ul>
</li>
<li>Multiple
<ul>
<li>Here we have one dependent variable to predict using multiple independent variables (features) for training and input.</li>
</ul>
</li>
<li>Multivariate
<ul>
<li>Similar to multilabel classification, there are multiple variables to predict (labels) with multiple independent variables for training and input. Accordingly, the input and output are vectors of numeric values.</li>
</ul>
</li>
</ul>
</li>
<li>Algorithms [spark](<a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html#regreschang">https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html#regreschang</a></li>
</ul>
<h3 id="62-unsupervised">6.2 Unsupervised<a aria-label="Link to this section" class="paige-header-link" href="#62-unsupervised"></a></h3>
<h4 id="621-frequent-pattern-mining">6.2.1 Frequent Pattern Mining<a aria-label="Link to this section" class="paige-header-link" href="#621-frequent-pattern-mining"></a></h4>
<ul>
<li>A type of association learning
<ul>
<li>based on identifying rules to uncover relationships between variables in the data. Association rule mining algorithms typically first look for frequent items in the dataset, then for frequent pairs or itemsets (e.g., items that are often viewed or purchased together). The rules follow the basic structure of antecedent (if) and consequent (then).</li>
</ul>
</li>
<li>Algorithms
<ul>
<li>FPGrowth</li>
<li>PrefixSpan: (MCKernel!)</li>
</ul>
</li>
</ul>
<h4 id="622-clustering">6.2.2 Clustering<a aria-label="Link to this section" class="paige-header-link" href="#622-clustering"></a></h4>
<ul>
<li>Common concepts
<ul>
<li>k = num clusters</li>
<li>some algo has a weightCol in trainingData that represents the data point&rsquo;s importance relative to the cluster center</li>
</ul>
</li>
<li>Algorithms
<ul>
<li>LDA
<ul>
<li>LDA (Latent Dirichlet Allocation) is a generic statistical algorithm used in evolutionary biology, biomedicine, and natural language processing. It expects a vector representing the counts of individual words in a document; since in our scenario we’re focusing on variables like fuel type, LDA does not match our data.</li>
</ul>
</li>
<li>GauusianMixture
<ul>
<li>The GaussianMixture algorithm is often used to identify the presence of a group within a bigger group. In our context, it could be useful for identifying the subgroups of different classes inside each car manufacturer’s group, such as the compact car class in the Audi group and the Bentley group. However, Gaussian​Mixture is known to perform poorly on high-dimensional data, making it hard for the algorithm to converge to a satisfying conclusion. Data is said to be high-dimensional when the number of features/columns is close to or larger than the number of observations/rows. For example, if I have five columns and four rows, my data is considered high-dimensional. In the world of large datasets, this is less likely to be the case.</li>
</ul>
</li>
<li>KMeans
<ul>
<li>KMeans is the most popular algorithm for clustering, due to its simplicity and efficiency. It takes a group of classes, creates random centers, and starts iterating over the data points and the centers, aiming to group similar data points together and find the optimal centers. The algorithm always converges, but the quality of the results depends on the number of clusters (k) and the number of iterations.</li>
</ul>
</li>
<li>PowerIterationClustering
<ul>
<li><code>PowerIterationClustering</code> (PIC) implements the <a href="https://oreil.ly/-Gu9c">Lin and Cohen algorithm</a>. It’s a scalable and efficient option for clustering vertices of a graph given pairwise similarities as edge properties. Note that this algorithm cannot be used in Spark pipelines as it does not yet implement the <code>Estimator</code>/<code>Transformer</code> pattern (more on that in <a href="https://learning.oreilly.com/library/view/scaling-machine-learning/9781098106812/ch06.html#ml_pipelines">“Machine Learning Pipelines”</a>).</li>
</ul>
</li>
</ul>
</li>
<li>Sample code (Gaussian mixture)</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">	<span class="n">k</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&#34;Make&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="kn">from</span> <span class="nn">pyspark.ml.clustering</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
</span></span><span class="line"><span class="cl">	<span class="n">gm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>                       <span class="n">featuresCol</span><span class="o">=</span><span class="s2">&#34;selectedFeatures&#34;</span><span class="p">,</span> <span class="n">maxIter</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">model</span> <span class="o">=</span> <span class="n">gm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="n">summary</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">summary</span> 
</span></span><span class="line"><span class="cl">	<span class="c1"># summary contains the predicted cluster centers, the transformed predictions, the cluster size (i.e., the number of objects in each cluster), and dedicated parameters based on the specific algorithm</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="n">summary</span><span class="o">.</span><span class="n">clusterSizes</span>
</span></span><span class="line"><span class="cl">	<span class="n">summary</span><span class="o">.</span><span class="n">logLikelihood</span>
</span></span><span class="line"><span class="cl">	
</span></span></code></pre></div><h3 id="63-evaluation">6.3 Evaluation<a aria-label="Link to this section" class="paige-header-link" href="#63-evaluation"></a></h3>
<ul>
<li>Spark has 6 different evaluators, each implementing the abstract class Evaulator</li>
</ul>
<h4 id="631-supervised">6.3.1 Supervised<a aria-label="Link to this section" class="paige-header-link" href="#631-supervised"></a></h4>
<ul>
<li>
<p>First calculates the confusion matrix</p>
<pre><code>  Predicted
</code></pre>
<p>ACTUAL		 -  TP      FN</p>
<ul>
<li>FP     TN</li>
</ul>
</li>
<li>
<p>Types</p>
<ul>
<li>BinaryClassicationEvaluator</li>
<li>MulticlassClassicationEvaluator</li>
<li>MultilabelClassicationEvaluator</li>
<li>RegressionEvaluator</li>
<li>RankingEvaluator</li>
</ul>
</li>
</ul>
<h4 id="632-unsupervised">6.3.2 Unsupervised<a aria-label="Link to this section" class="paige-header-link" href="#632-unsupervised"></a></h4>
<ul>
<li>
<p>Computes the silhouette measure</p>
<ul>
<li>It expects two input columns, prediction and features, and an optional weight column. It computes the Silhouette measure, where you can choose between two distance measures: squaredEuclidean and cosine. ==Silhouette is a method to evaluate the consistency and validity of the clusters==; it does this by calculating the distance between each data point and the other data points in its cluster and comparing this to its distance from the points in other clusters.</li>
</ul>
</li>
<li>
<p>Code</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.ml.evaluation</span> <span class="kn">import</span> <span class="n">ClusteringEvaluator</span>
</span></span><span class="line"><span class="cl"><span class="n">evaluator</span> <span class="o">=</span> <span class="n">ClusteringEvaluator</span><span class="p">(</span><span class="n">featuresCol</span><span class="o">=</span><span class="s1">&#39;selectedFeatures&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">evaluator</span><span class="o">.</span><span class="n">setPredictionCol</span><span class="p">(</span><span class="s2">&#34;prediction&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># compare kmeans vs gm</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;kmeans: &#34;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">kmeans_predictions</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;GM: &#34;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gm_predictions</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">	<span class="n">kmeans</span><span class="p">:</span> <span class="mf">0.7264903574632652</span>
</span></span><span class="line"><span class="cl">	<span class="n">GM</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.1517797715036008</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">evaluator</span><span class="o">.</span><span class="n">isLargerBetter</span><span class="p">()</span> <span class="c1"># true or false</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># sets the distance measurement</span>
</span></span><span class="line"><span class="cl"><span class="n">evaluator</span><span class="o">.</span><span class="n">setDistanceMeasure</span><span class="p">(</span><span class="s2">&#34;cosine&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;kmeans: &#34;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">kmeans_predictions</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;GM: &#34;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gm_predictions</span><span class="p">)))</span>
</span></span></code></pre></div><h3 id="64-hyperparameter-and-tuning-experiments">6.4 Hyperparameter and Tuning Experiments<a aria-label="Link to this section" class="paige-header-link" href="#64-hyperparameter-and-tuning-experiments"></a></h3>
<h4 id="option-1-parameter-grid">Option 1: Parameter Grid<a aria-label="Link to this section" class="paige-header-link" href="#option-1-parameter-grid"></a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Build grid</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.ml.tuning</span> <span class="kn">import</span> <span class="n">ParamGridBuilder</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">grid</span> <span class="o">=</span> <span class="n">ParamGridBuilder</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">		<span class="o">.</span><span class="n">addGrid</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">maxIter</span><span class="p">,</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">])</span> 
</span></span><span class="line"><span class="cl">        <span class="o">.</span><span class="n">addGrid</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">distanceMeasure</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;euclidean&#39;</span><span class="p">,</span><span class="s1">&#39;cosine&#39;</span><span class="p">])</span> 
</span></span><span class="line"><span class="cl">        <span class="o">.</span><span class="n">addGrid</span><span class="p">(</span><span class="n">evaluator</span><span class="o">.</span><span class="n">distanceMeasure</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;euclidean&#39;</span><span class="p">,</span><span class="s1">&#39;cosine&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>    
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Split data into training and test</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.ml.tuning</span> <span class="kn">import</span> <span class="n">TrainValidationSplit</span>
</span></span><span class="line"><span class="cl"><span class="n">tvs</span> <span class="o">=</span> <span class="n">TrainValidationSplit</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">kmeans</span><span class="p">,</span> <span class="n">estimatorParamMaps</span><span class="o">=</span><span class="n">grid</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                           <span class="n">evaluator</span><span class="o">=</span><span class="n">evaluator</span><span class="p">,</span> <span class="n">collectSubModels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tvs_model</span> <span class="o">=</span> <span class="n">tvs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># See results</span>
</span></span><span class="line"><span class="cl"><span class="n">tvs_model</span><span class="o">.</span><span class="n">validationMetrics</span>
</span></span></code></pre></div><h4 id="option-2-cross-validation">Option 2: Cross Validation<a aria-label="Link to this section" class="paige-header-link" href="#option-2-cross-validation"></a></h4>
<ul>
<li>Cross validation enables use to try different multiple combiation of data splits; BUT will be compute intensive</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.ml.tuning</span> <span class="kn">import</span> <span class="n">CrossValidator</span>
</span></span><span class="line"><span class="cl"><span class="n">cv</span> <span class="o">=</span> <span class="n">CrossValidator</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">kmeans</span><span class="p">,</span> <span class="n">estimatorParamMaps</span><span class="o">=</span><span class="n">grid</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                    <span class="n">evaluator</span><span class="o">=</span><span class="n">evaluator</span><span class="p">,</span> <span class="n">collectSubModels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                    <span class="n">parallelism</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">numFolds</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cv_model</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="65-ml-pipellines">6.5 ML Pipellines<a aria-label="Link to this section" class="paige-header-link" href="#65-ml-pipellines"></a></h3>
<ul>
<li>Spark Concepts
<ul>
<li>Transformers = A function that converts data in some wa</li>
<li>Estimator = an algorithm</li>
<li>Pipeline = sequence of transformer and estimator</li>
</ul>
</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">	<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c1"># transformer: hasher, selector</span>
</span></span><span class="line"><span class="cl">	<span class="c1"># estimator: gm</span>
</span></span><span class="line"><span class="cl">	<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">hasher</span><span class="p">,</span> <span class="n">selector</span><span class="p">,</span> <span class="n">gm</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="c1"># Fit the pipeline to training data</span>
</span></span><span class="line"><span class="cl">	<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span></code></pre></div><h1 id="7-bridging-spark-and-dl-frameworks">7 Bridging Spark and DL Frameworks<a aria-label="Link to this section" class="paige-header-link" href="#7-bridging-spark-and-dl-frameworks"></a></h1>
<h3 id="2-cluster-approach">2 Cluster Approach<a aria-label="Link to this section" class="paige-header-link" href="#2-cluster-approach"></a></h3>
<ul>
<li>
<p>Spark philosophy makes it ideal to data processing and feature engineering</p>
<ul>
<li>==<code>the size of the cluster changes the duration of the job, not its capacity to run an algorithm</code>==</li>
<li>Spark’s limitations are mostly bound to its underlying premise that all algorithm implementations must be able to scale without limit, which requires the model to be able to perform its learning process at scale</li>
</ul>
</li>
<li>
<p>In a two cluster approach</p>
<ul>
<li>cluster 1: Spark cluster</li>
<li>cluster 2: DL distributed cluaster</li>
<li>(cluster1: Spark) &lt;&ndash; (S3, HDFS, GCP storage) &ndash;&gt; (cluster2: DL)</li>
</ul>
</li>
<li>
<p>Monoids</p>
<ul>
<li>A monoid is an algebraic structure that includes a set, an associative binary operation, and an identity element
From a programming standpoint, monoids enable developers to break up a task into smaller subtasks almost arbitrarily,
<ul>
<li>So what? Break up enables us to decouple logic.  One use case is to delay the error handling to a common piece of code, Either error handling pattern</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="data-access-layer">Data Access Layer<a aria-label="Link to this section" class="paige-header-link" href="#data-access-layer"></a></h3>
<ul>
<li>
<p>Why need Data Access Layer (DAL)</p>
<ul>
<li>If we use the best toool for each
<ul>
<li>Spark for data processing, feature engineering</li>
<li>Torch &amp; Tensorflow for distributed training</li>
</ul>
</li>
<li>we need to have a way to transfrom between the different data formats</li>
</ul>
</li>
<li>
<p>DAL feature requirements</p>
<ul>
<li>Distributed systems:
<ul>
<li>It should be able to leverage existing systems to enable scaling.</li>
</ul>
</li>
<li>Rich software ecosystem:
<ul>
<li>This allows it to grow to encompass new machine learning frameworks and ensures that it will continue to be supported, bugs will be fixed, and new features will be developed.</li>
</ul>
</li>
<li>Columnar file formats:
<ul>
<li>Columnar file formats store data by column, not by row, which allows greater efficiency when filtering on specific fields during the training and testing process.</li>
</ul>
</li>
<li>Row filtering
<ul>
<li>Some machine learning algorithms require sampling specific rows, so we need a mechanism to filter on rows, not only on columns.</li>
</ul>
</li>
<li>Data versioning
<ul>
<li>It should be possible to travel back in time, to support reproducibility of experiments.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Author discusses open source Petastorm as DAL</p>
</li>
</ul>
<h1 id="8-tensorflow-distributed-machine-learning">8 Tensorflow Distributed Machine Learning<a aria-label="Link to this section" class="paige-header-link" href="#8-tensorflow-distributed-machine-learning"></a></h1>
<ul>
<li>This section relates to (distributed) training</li>
</ul>
<h1 id="9-pytorch-distributed-machine-learning">9 Pytorch Distributed Machine Learning<a aria-label="Link to this section" class="paige-header-link" href="#9-pytorch-distributed-machine-learning"></a></h1>
<ul>
<li>This section relates to (distributed) training</li>
</ul>
<h1 id="10-deployment-patterns">10 Deployment Patterns<a aria-label="Link to this section" class="paige-header-link" href="#10-deployment-patterns"></a></h1>
<h3 id="101-deployment-patterns">10.1 Deployment Patterns<a aria-label="Link to this section" class="paige-header-link" href="#101-deployment-patterns"></a></h3>
<h3 id="102-monitoring-ml-models-in-production">10.2 Monitoring ML Models In Production<a aria-label="Link to this section" class="paige-header-link" href="#102-monitoring-ml-models-in-production"></a></h3>
<ul>
<li>Data Drift
<ul>
<li>Definition:
<ul>
<li>the data you’re feeding to the online algorithm has changed in some way relative to the training data</li>
</ul>
</li>
<li>Can occur any time the data structure, semantics, or infrastructure change unexpectedly</li>
<li>Modes
<ul>
<li>Instantaneous</li>
<li>Gradual</li>
<li>Periodic : Ebay&rsquo;s weekend traffic is different from weekdays</li>
<li>Temporary Drift</li>
</ul>
</li>
</ul>
</li>
<li>Model Drift, Concept Drift
<ul>
<li>Changes in real-world environments often result in model drift, which diminishes the predictive power of the model. Many things may cause this, ranging from changes in the digital environment (leading to changes in relationships between model variables) to changes in user demographics or behaviors.</li>
<li>Detection of model drift is known to be a hard problem and often requires human interaction. It’s important to work with users, customers, product managers, and data analysts to better understand the changes that may affect the usefulness of the model</li>
</ul>
</li>
<li>Distributional Domain Shift (the long tail)
<ul>
<li>Domain shift refers to a difference between the distribution in the training dataset and the data the model encounters when deployed</li>
<li>Another way to look at it is to acknowledge that the sampling data may not represent all the parts of the distribution that we care about.</li>
<li>A domain shift can happen because of bugs in the training data pipeline or bias in the sampling proces</li>
<li>distribution of the training data does not accurately represent real-world data anymore</li>
<li>==watch for differences between the training distribution and the production data distribution==</li>
</ul>
</li>
<li>What Metrics To Monitor
<ul>
<li>Model Metrics
<ul>
<li>accuracy, robustness, performance</li>
<li>May be hard to collect in proudction since we may not have all the required data
<ul>
<li>Ex: if supervised model, what is our label?</li>
</ul>
</li>
</ul>
</li>
<li>Business Metrics
<ul>
<li>These show the impact of the machine learning system on the business. For example, for a recommendation system, we would monitor various metrics related to user churn and user engagement: how many people are using the system, how frequently, and for how long in each interaction. We can even split the user base into multiple user groups and run A/B testing of different models in production. Monitoring business metrics is often fairly straightforward, as many organizations already have a business intelligence (BI) or analytics team that measures them. However, there may be conflicting or hidden factors that affect these metrics, so it’s best to combine these with other measures</li>
</ul>
</li>
<li>Model prediction vs actual behavior
<ul>
<li>These metrics show how well the model’s predictions correlate with actual user or system behavior. Measuring them typically requires some creativity and tailor-made solutions, as it involves capturing real behaviors rather than predicted ones. Often, we will want to create a separate data pipeline to capture and save actual behavior into a dataset</li>
</ul>
</li>
<li>Hardware/networking metrics</li>
</ul>
</li>
<li>How Do I Measure Changines Using My Monitoring System?
<ul>
<li>Goal: detect changes over time</li>
<li>Define a reference to compare to
<ul>
<li>validation and training data</li>
<li>production window over a period you believe to be healthy</li>
</ul>
</li>
<li>Measure the reference over a time period</li>
<li>Algorithms for measurement
<ul>
<li>Rule based distance metrics
<ul>
<li>These measure how far the data is from the reference, given a set of rules. They’re great for determining the quality of the data. We can compare minimum, maximum, and mean values and check that they are within the acceptable/allowable range. We can also check the number of data points to confirm data isn’t missing or being dropped (for example, due to bad preprocessing), check for the presence of null values, and monitor for data drift.</li>
</ul>
</li>
<li>D1 distance
<ul>
<li>This is a classic distance metric that calculates the sum of the distances between the fixed data values. It’s easy to interpret and simplifies monitoring in general.</li>
</ul>
</li>
<li>Kolmogorov-Smirnov statistic
<ul>
<li>This finds the distance between the empirical and cumulative distribution functions. It’s a commonly used metric that is relatively easy to interpret and plot on a chart.</li>
</ul>
</li>
<li>Kullback-Leibler Divergence
<ul>
<li>This measures the difference between two probability distributions over the same variable x. It’s a statistical log-based equation that is sensitive to the tails of the distribution. It detects outliers but is a bit difficult to comprehend and interpret. This metric can be useful when you’re fully informed about how to use it, but it won’t provide much insight in most cases.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>What it look like in production
<ul>
<li>Data check
<ul>
<li>reference vs recent data &ndash;&gt; data eval &ndash;&gt; drift? &ndash;&gt; retrain</li>
</ul>
</li>
<li>Model
<ul>
<li>prediction vs actual &ndash;&gt; model eval &ndash;&gt; drifit? &ndash;&gt; retrain</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="103-production-feedback-loop">10.3 Production Feedback Loop<a aria-label="Link to this section" class="paige-header-link" href="#103-production-feedback-loop"></a></h3>
<ul>
<li>A feedback loop is when the system saves the outputs of the model and the corresponding end user actions as observed data and uses this data to retrain and improve the model over time</li>
<li><a href="https://arxiv.org/pdf/2104.00087.pdf">UBER Paper</a></li>
</ul>
<h3 id="104-deploying-with-mllib">10.4 Deploying with MLLib<a aria-label="Link to this section" class="paige-header-link" href="#104-deploying-with-mllib"></a></h3>
<ul>
<li>Log MLLib models parameters</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-scala" data-lang="scala"><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="k">#</span> <span class="nc">Metadata</span>
</span></span><span class="line"><span class="cl">	<span class="o">(</span><span class="s">&#34;timestamp&#34;</span> <span class="o">-&gt;</span> <span class="nc">System</span><span class="o">.</span><span class="n">currentTimeMillis</span><span class="o">())</span>
</span></span><span class="line"><span class="cl">	<span class="o">(</span><span class="s">&#34;sparkVersion&#34;</span> <span class="o">-&gt;</span> <span class="n">sc</span><span class="o">.</span><span class="n">version</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">	<span class="o">(</span><span class="s">&#34;uid&#34;</span> <span class="o">-&gt;</span> <span class="n">uid</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">	<span class="o">(</span><span class="s">&#34;paramMap&#34;</span> <span class="o">-&gt;</span> <span class="n">jsonParams</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">	<span class="o">(</span><span class="s">&#34;defaultParamMap&#34;</span> <span class="o">-&gt;</span> <span class="n">jsonDefaultParams</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="k">#</span> <span class="nc">Model</span> <span class="n">params</span>
</span></span><span class="line"><span class="cl">	<span class="s">&#34;numFeatures&#34;</span>
</span></span><span class="line"><span class="cl">	<span class="s">&#34;numClasses&#34;</span>
</span></span><span class="line"><span class="cl">	<span class="s">&#34;numTrees&#34;</span>
</span></span></code></pre></div><h3 id="105-deploying-with-mlflow">10.5 Deploying with MLFlow<a aria-label="Link to this section" class="paige-header-link" href="#105-deploying-with-mlflow"></a></h3>
<h4 id="1051-step1-wrap-model-and-meta-in-a-mlflow-wrapper">10.5.1 Step1: Wrap model and meta in a MLflow Wrapper<a aria-label="Link to this section" class="paige-header-link" href="#1051-step1-wrap-model-and-meta-in-a-mlflow-wrapper"></a></h4>
<pre><code>- Code 1: python wrapper code needs to implement `mlflow.pyfunc.PyFuncModel`
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MyModelWrapper</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">	<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	    <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span> <span class="o">=</span> <span class="n">model_path</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">def</span> <span class="nf">load_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	    <span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_uri</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">model_input</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl">	    <span class="kn">import</span> <span class="nn">json</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	    <span class="n">class_def</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	        <span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;212.teapot&#39;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">	        <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;234.tweezer&#39;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">	        <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;196.spaghetti&#39;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">	        <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;249.yo-yo&#39;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">	    <span class="p">}</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	    <span class="n">rtn_df</span> <span class="o">=</span> <span class="n">model_input</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	    <span class="n">rtn_df</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">	    <span class="n">rtn_df</span><span class="p">[</span><span class="s1">&#39;probabilities&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">model_input</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">	        <span class="c1"># resize and reshape the image</span>
</span></span><span class="line"><span class="cl">	        <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;origin&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl">	                                  <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">	        <span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">	      
</span></span><span class="line"><span class="cl">	        <span class="c1"># predict</span>
</span></span><span class="line"><span class="cl">	        <span class="n">class_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	        <span class="c1"># take the class with the highest probability</span>
</span></span><span class="line"><span class="cl">	        <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">class_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	        <span class="n">class_prob_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	        <span class="c1"># calculate probability for each class option:</span>
</span></span><span class="line"><span class="cl">	        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">class_def</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">	            <span class="n">class_prob_dict</span><span class="p">[</span><span class="n">val</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">(</span><span class="n">class_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="nb">int</span><span class="p">(</span><span class="n">key</span><span class="p">)]),</span> 
</span></span><span class="line"><span class="cl">	                                                     <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	        <span class="n">rtn_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index</span><span class="p">,</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">classes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">	        <span class="n">rtn_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index</span><span class="p">,</span><span class="s1">&#39;probabilities&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">class_prob_dict</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	    <span class="k">return</span> <span class="n">rtn_df</span><span class="p">[[</span><span class="s1">&#39;prediction&#39;</span><span class="p">,</span> <span class="s1">&#39;probabilities&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>- Code 2: to save model
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">	<span class="n">model_path</span> <span class="o">=</span> <span class="s2">&#34;.../mlruns/</span><span class="si">{experiment_id}</span><span class="s2">/</span><span class="si">{run_id}</span><span class="s2">/artifacts/models&#34;</span>
</span></span><span class="line"><span class="cl">	<span class="n">wrappedModel</span> <span class="o">=</span> <span class="p">{</span><span class="n">some_class</span><span class="p">}(</span><span class="n">model_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="s2">&#34;pyfunc_model_v2&#34;</span><span class="p">,</span> <span class="n">python_model</span><span class="o">=</span><span class="n">wrappedModel</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="c1"># Output</span>
</span></span><span class="line"><span class="cl">		<span class="o">---</span> <span class="mi">58</span><span class="n">dc6db17fb5471a9a46d87506da983f</span>
</span></span><span class="line"><span class="cl">		<span class="o">-------</span> <span class="n">artifacts</span>
</span></span><span class="line"><span class="cl">		<span class="o">------------</span> <span class="n">model</span>
</span></span><span class="line"><span class="cl">		<span class="o">------------</span> <span class="n">MLmodel</span>
</span></span><span class="line"><span class="cl">		<span class="o">-------------</span> <span class="n">conda</span><span class="o">.</span><span class="n">yaml</span>
</span></span><span class="line"><span class="cl">		<span class="o">-------------</span> <span class="n">input_example</span><span class="o">.</span><span class="n">json</span>
</span></span><span class="line"><span class="cl">		<span class="o">-------------</span> <span class="n">model</span><span class="o">.</span><span class="n">pkl</span>
</span></span><span class="line"><span class="cl">		<span class="o">-------</span> <span class="n">meta</span><span class="o">.</span><span class="n">yaml</span>
</span></span><span class="line"><span class="cl">		<span class="o">-------</span> <span class="n">metrics</span>
</span></span><span class="line"><span class="cl">		<span class="o">------------</span> <span class="n">training_score</span>
</span></span><span class="line"><span class="cl">		<span class="o">-------</span> <span class="n">params</span>
</span></span><span class="line"><span class="cl">		<span class="o">------------</span> <span class="n">A</span>
</span></span><span class="line"><span class="cl">		<span class="o">------------</span> <span class="o">...</span>
</span></span><span class="line"><span class="cl">		<span class="o">-------</span> <span class="n">tags</span>
</span></span><span class="line"><span class="cl">		<span class="o">------------</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">source</span><span class="o">.</span><span class="n">type</span>
</span></span><span class="line"><span class="cl">		<span class="o">------------</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">user</span>
</span></span></code></pre></div><h4 id="1052-option1-deploy-as-a-model-service">10.5.2 Option1: Deploy as a model service<a aria-label="Link to this section" class="paige-header-link" href="#1052-option1-deploy-as-a-model-service"></a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">	<span class="c1"># load model as a service</span>
</span></span><span class="line"><span class="cl">	<span class="n">model_path</span> <span class="o">=</span> <span class="s2">&#34;.../mlruns/</span><span class="si">{experiment_id}</span><span class="s2">/</span><span class="si">{run_id}</span><span class="s2">/artifacts/models&#34;</span>
</span></span><span class="line"><span class="cl">	<span class="n">model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model_input</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="1053-option2-dploy-as-spark-udf">10.5.3 Option2: Dploy as Spark UDF<a aria-label="Link to this section" class="paige-header-link" href="#1053-option2-dploy-as-spark-udf"></a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">	<span class="c1"># Load model as a Spark UDF</span>
</span></span><span class="line"><span class="cl">	<span class="n">loaded_model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">spark_udf</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="n">mlflow_model_path</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">	                                       <span class="n">result_type</span><span class="o">=</span><span class="n">ArrayType</span><span class="p">(</span><span class="n">StringType</span><span class="p">()))</span>
</span></span><span class="line"><span class="cl">	<span class="c1"># Predict on a Spark DataFrame</span>
</span></span><span class="line"><span class="cl">	<span class="n">scored_df</span> <span class="o">=</span> <span class="p">(</span><span class="n">images_df</span>
</span></span><span class="line"><span class="cl">             <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;origin&#39;</span><span class="p">,</span> <span class="n">col</span><span class="p">(</span><span class="s2">&#34;content&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">             <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;my_predictions&#39;</span><span class="p">,</span> <span class="n">loaded_model</span><span class="p">(</span><span class="n">struct</span><span class="p">(</span><span class="s2">&#34;origin&#34;</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">             <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;origin&#34;</span><span class="p">))</span>
</span></span></code></pre></div></div>


    </div>
</article>




    
    



    



    



    



    



    



    



    



    







                        
                    </main>

                    









    

    


<footer class="mb-3" id="paige-footer">
    

    
        <div class="mb-3" id="paige-prev-next">
            

            
                <p class="mb-0 text-center text-secondary" id="paige-prev">
                    &lsaquo; <a class="link-secondary" href="https://example.com/books/software-system/learning-go/">Learning Go</a>
                </p>
            
        </div>
    

    

    

    

    
</footer>

                </div>
            </div>
        </div>

        















    
    
    


<script  crossorigin="anonymous"   defer  integrity="sha256-gfPiYYSP&#43;RNtNeRBt45mJombFJmNf0V0Ipu785Obi0M="   referrerpolicy="no-referrer"  src="/js/paige/bootstrap/bootstrap.bundle.min.81f3e261848ff9136d35e441b78e6626899b14998d7f4574229bbbf3939b8b43.js" ></script>



    













    
    
    


<script  crossorigin="anonymous"   defer  integrity="sha256-kqnbKZyzZFmn0J2JtRxwdeNh0b3FknYDyAd&#43;mGKI73c="   referrerpolicy="no-referrer"  src="/js/paige/katex/katex.min.min.92a9db299cb36459a7d09d89b51c7075e361d1bdc5927603c8077e986288ef77.js" ></script>

    













    
    
    


<script  crossorigin="anonymous"   defer  integrity="sha256-pQMCGuz&#43;5jpyog4zEVyH/xvxJRsPM9M7d7t6&#43;TiyEA8="  onload="renderMathInElement(document.body);"   referrerpolicy="no-referrer"  src="/js/paige/katex/auto-render.min.min.a503021aecfee63a72a20e33115c87ff1bf1251b0f33d33b77bb7af938b2100f.js" ></script>






    



    



    



    



    



    



    



    



    



    



    



    



    



    



    





<noscript>JavaScript is required</noscript>


        
    </body>
</html>
